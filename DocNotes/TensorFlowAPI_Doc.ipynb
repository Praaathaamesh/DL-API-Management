{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AbuGvMKkJWW-",
        "y85eeHx2LnGW"
      ],
      "authorship_tag": "ABX9TyOREX8Eb38LOUrHq5ULMeQm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praaathaamesh/DL-API-Management/blob/main/DocNotes/TensorFlowAPI_Doc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intoroduction to ML Fundamentals"
      ],
      "metadata": {
        "id": "yw3F83cAE_SJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Initially the AI was set of predefined tool\n",
        "* Very good AI = Very good rules implemented into it\n",
        "* Hence, not complex, but can execute complex intellectual tasks\n",
        "* ML is subset of AI\n",
        "* ML, rather than us giving program the rules, first figures out the rules for us! may not necessarily get the correct answer every time.\n",
        "* NN are hyped. Form of ML using layered representation of data. has more than two layers. Multi-stage multi-layer information extraction process.\n",
        "* Not modelled after the brain!\n",
        "* Data is really important!\n",
        "* input = features ; desired output = labels\n",
        "* Data must be correct."
      ],
      "metadata": {
        "id": "r4SpdhNlFSIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ],
      "metadata": {
        "id": "AbuGvMKkJWW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tensor = Primary aspect of TF. A vector generalised to higher dimensions. Basically datapoint. Vector can have many dimensions.\n",
        "* Each tensore represents a partially defined computation that will eventually produce a value.\n",
        "* Each tensor has a datatype and a shape (Dimensions of data)."
      ],
      "metadata": {
        "id": "lrd8RKnjJc1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing TensorFlow"
      ],
      "metadata": {
        "id": "y85eeHx2LnGW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-A671UmEcsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3daa32b6-8126-4b3e-9f45-fd39e04998ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The version of TF:  2.19.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"The version of TF: \", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([[1,2,3], [4,5,6]])\n",
        "print(x)\n",
        "# Most important attributes of constants are shape and dtype\n",
        "print(x.shape)\n",
        "print(x.dtype)\n",
        "# rank function to fid out rank of the constant tensor variable\n",
        "print(tf.rank(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAwAy8IgWtAg",
        "outputId": "0be187cd-6116-456f-bc46-d4f2003e0e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n",
            "(2, 3)\n",
            "<dtype: 'int32'>\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x+x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CTqhyysXV8q",
        "outputId": "6683f567-0187-419f-9b7b-85486ce0e103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 2  4  6]\n",
            " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(5 * x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qlcg4rEAXaQw",
        "outputId": "bbf78540-8ee6-4609-d550-18ba9e8d768a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 5 10 15]\n",
            " [20 25 30]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.transpose(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBpIq6O9Xcby",
        "outputId": "feb327da-163a-4ccf-bb78-a9254eef222f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 4]\n",
            " [2 5]\n",
            " [3 6]], shape=(3, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.concat([x,x,x,x], axis = 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gu3dzcoYav0",
        "outputId": "5f640776-6f24-49b3-9846-e5ef18a17413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [1 2 3]\n",
            " [4 5 6]\n",
            " [1 2 3]\n",
            " [4 5 6]\n",
            " [1 2 3]\n",
            " [4 5 6]], shape=(8, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.nn.softmax([1.,-1.,0.], axis =-1) # Softmax activation function gives numbers whose sum is 1\n",
        "# multidimensional prediciton aspects"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yppUav1PYuFd",
        "outputId": "e2553f9d-28ad-4bdf-d18f-452c674f6f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.6652409 , 0.09003057, 0.24472845], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce sum can only be calculated for anything but constants\n",
        "\n",
        "print(tf.reduce_sum(tf.convert_to_tensor([1,2,3]))) # only tensor input or this is needed a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvriEDf8aOJ1",
        "outputId": "d6c8e337-077c-4e0d-ae80-f97930c7dcc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.config.list_logical_devices(\"GPU\"):\n",
        "  print(\"is using the GPU\")\n",
        "else:\n",
        "  print(\"is not using the GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qYX2-e8bDWw",
        "outputId": "75354971-4660-45ad-a9be-3a1ae1f2b062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is not using the GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Tensors\n",
        "\n",
        "Below is the example of how to create multiple tensors of different datatypes."
      ],
      "metadata": {
        "id": "B6HdJwysL7W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "String = tf.Variable(\"This is a string\", tf.string)\n",
        "Number = tf.Variable(324, tf.int16)\n",
        "Floating = tf.Variable(3.55, tf.float64)"
      ],
      "metadata": {
        "id": "PIOzPfECMIjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(String, '\\n', Number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97KXktp2L7Co",
        "outputId": "565b5172-cbde-466e-b528-4f516a10586b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=string, numpy=b'This is a string'> \n",
            " <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=324>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfvar = tf.Variable([0.0, 0.0, 0.0]) # Creating the variable\n",
        "print(tfvar, '\\n')\n",
        "\n",
        "tfvar.assign([9.9, 9.9, 9.9]) # assigning the tensor elemenet of same dimensions\n",
        "print(tfvar, '\\n')\n",
        "\n",
        "tfvar.assign_add([0.1,0.1,0.1]) # adding the tensor elements to the pre-existing tensor\n",
        "print(tfvar, '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZvD14pkbaR4",
        "outputId": "40db9255-92df-4239-ca5f-5318d52f1cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)> \n",
            "\n",
            "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([9.9, 9.9, 9.9], dtype=float32)> \n",
            "\n",
            "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([10., 10., 10.], dtype=float32)> \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic Differentiation/Derivations"
      ],
      "metadata": {
        "id": "G__w6mjNdpW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for variable xvar\n",
        "xvar = tf.Variable(1.0)\n",
        "def f(x):\n",
        "  y = x**2 + 2*x - 5\n",
        "  return y\n",
        "print(f(xvar))\n",
        "\n",
        "# Differentiate the function w.r.t xvar\n",
        "with tf.GradientTape() as tape:\n",
        "  Diff = tape.gradient(f(xvar), xvar)\n",
        "print(Diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn3o1QtedeHh",
        "outputId": "78253e1f-874a-4be5-b6e7-4b55f0655df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(-2.0, shape=(), dtype=float32)\n",
            "tf.Tensor(4.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rank/Degree of Tensors\n",
        "\n",
        "Number of dimensions involved in a tensor. The tensor of rank 0 is a scalar. Rank 1 is a vector and anything above rank 2 is a matrix."
      ],
      "metadata": {
        "id": "3ou8fO-RMxrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R1_tensor = tf.Variable(['A'], tf.string)\n",
        "R2_tensor = tf.Variable([['A'],['B']], tf.string)"
      ],
      "metadata": {
        "id": "oRA9oIdlNlIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(R1_tensor, '\\n', R2_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPObZNxPOS89",
        "outputId": "a7a48fe9-9314-4baf-9c29-8884a7bd54cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(1,) dtype=string, numpy=array([b'A'], dtype=object)> \n",
            " <tf.Variable 'Variable:0' shape=(2, 1) dtype=string, numpy=\n",
            "array([[b'A'],\n",
            "       [b'B']], dtype=object)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.rank(R1_tensor))\n",
        "print(tf.rank(R2_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZf2ldBMN-2p",
        "outputId": "efeff885-307e-4396-f2bb-ca7296c90502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shape of a tensor\n",
        "\n",
        "How many items we have in each dimensions."
      ],
      "metadata": {
        "id": "C0oY2asAOeYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.shape(R1_tensor))\n",
        "print(tf.shape(R2_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIssAfsJOxXb",
        "outputId": "49352b13-2338-472b-a873-788335ad206b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "tf.Tensor([2 1], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively by using shape method directly\n",
        "print(R1_tensor.shape)\n",
        "print(R2_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys7eentZPC-i",
        "outputId": "6dfa0bd3-770e-4bb4-eeb8-399526d904e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1,)\n",
            "(2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing shape of a Tensor\n",
        "\n",
        "We will do it alot of times. Number of elements of a tensor is product of sizes of all its shapes."
      ],
      "metadata": {
        "id": "1w8fQtG0PRD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OneTensor = tf.ones([1,2,3]) # creates a tensor of shape [1,2,3] of ones.\n",
        "print(OneTensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cKEtGHjPvWR",
        "outputId": "dbf276ee-a51c-405d-b460-a6b8ad76e890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1. 1. 1.]\n",
            "  [1. 1. 1.]]], shape=(1, 2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape it in [2,3,1]\n",
        "TwoTensor = tf.reshape(OneTensor, [2, 3, 1])\n",
        "print(TwoTensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUkkacAtQM8I",
        "outputId": "24ef7321-37f3-4fd8-8aca-4f9f8a674ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]]], shape=(2, 3, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape it in [3, -1]\n",
        "# -1 tells the tensor to calculate the size of the tensor in that place\n",
        "ThreeTensor = tf.reshape(TwoTensor, [3, -1])\n",
        "print(ThreeTensor)\n",
        "\n",
        "'''\n",
        "New shape will be [3,2], because here TwoTensor has 6 elements\n",
        "3 defines the number of lists and -1 tells to take the sutable shape automatically\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RMZ77Wg6RcZ1",
        "outputId": "2a0d49eb-5d21-4907-ce01-4005f56f3e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]], shape=(3, 2), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNew shape will be [3,2], because here TwoTensor has 6 elements\\n3 defines the number of lists and -1 tells to take the sutable shape automatically\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IEFxIoIKa-Qf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Types of Tensors\n",
        "\n",
        "**Variable, Constant, Placeholder, SparseTensor**.\n",
        "All of them are immutable; not the Variable"
      ],
      "metadata": {
        "id": "OHnpDgpDRYWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us look at a Constant\n",
        "C1 = tf.constant(1, tf.int16)\n",
        "print(C1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqWfpUx7T1pa",
        "outputId": "bdd78526-f0d8-41af-daf1-b784ad5d9671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Everything Tensors"
      ],
      "metadata": {
        "id": "7VMjP8H5GqUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "27yl1cyKGxSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [2] = scalar (no rows or columns, hence rank 0)\n",
        "# [2.0, 4.4, 7.2] = vector (linear array, hence rank 1)\n",
        "# [[[2.5, 6.8, 1.8], [2.5, 6.8, 1.8]], [[2.5, 6.8, 1.8], [3.3, 6.9, 2.1]]] = 3D matrix (2 rows 3 columns, hence rank 3) Could be multidimensional\n",
        "# [[2.2, 3.4],[2.3, 6.7]] = 2D matrix (2 rows 2 columns, hence rank 2)\n",
        "# number of columns == rank\n",
        "# Tensors could contain float, int, complex and even strings"
      ],
      "metadata": {
        "id": "KGYIhJ1IJamf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create first tensor\n",
        "TensorConstant_rank0 = tf.constant(3.0)\n",
        "print(TensorConstant_rank0)\n",
        "# default is float32 dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc-_RRJEHP5o",
        "outputId": "c940cd6a-416e-4222-84bf-55731be06ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create rank 1 tensor\n",
        "TensorConstant_rank1 = tf.constant([2.0, 4.4, 8.2])\n",
        "print(TensorConstant_rank1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4jVxNxzHsMZ",
        "outputId": "b2cfc780-e967-4479-a6ee-8ea243bbc0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2.  4.4 8.2], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create rank 2 tensor\n",
        "TensorConstant_rank2 = tf.constant([[2.2, 3.4],[2.3, 6.7]])\n",
        "print(TensorConstant_rank2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiopc8tcIJDS",
        "outputId": "642b8803-3aa6-4a39-9f18-82444873318f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2.2 3.4]\n",
            " [2.3 6.7]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensors can have arbitrary number of axes or dimensions\n",
        "\n",
        "TensorConstant_rank3 = tf.constant([[[2.5, 6.8, 1.8], [2.5, 6.8, 1.8]], [[2.5, 6.8, 1.8], [3.3, 6.9, 2.1]]])\n",
        "print(TensorConstant_rank3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-inMrWbI0pt",
        "outputId": "508af7fe-5c3b-4dd9-ea79-5a4dca142172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[2.5 6.8 1.8]\n",
            "  [2.5 6.8 1.8]]\n",
            "\n",
            " [[2.5 6.8 1.8]\n",
            "  [3.3 6.9 2.1]]], shape=(2, 2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Arithematic operations (element wise addition/substraction/multiplication, matrix multiplication)\n",
        "\n",
        "a = tf.constant([[[2.5, 4.9], [0.3,3.3]], [[7.0, 2.0], [1.0, 2.7]]])\n",
        "b = tf.constant([[[2.5, 4.9], [0.3,3.3]], [[7.0, 2.0], [1.0, 2.7]]])\n",
        "\n",
        "print(a + b, '\\n')\n",
        "print(a - b, '\\n')\n",
        "print(a * b, '\\n')\n",
        "print(a @ b, '\\n')\n",
        "\n",
        "print(tf.add(a, b))\n",
        "print(tf.multiply(a, b))\n",
        "print(tf.matmul(a, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyIO31UdKqlc",
        "outputId": "0ed78251-87a8-49b9-97ab-238add393861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 5.   9.8]\n",
            "  [ 0.6  6.6]]\n",
            "\n",
            " [[14.   4. ]\n",
            "  [ 2.   5.4]]], shape=(2, 2, 2), dtype=float32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[[0. 0.]\n",
            "  [0. 0.]]\n",
            "\n",
            " [[0. 0.]\n",
            "  [0. 0.]]], shape=(2, 2, 2), dtype=float32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[[ 6.25      24.01     ]\n",
            "  [ 0.09      10.889999 ]]\n",
            "\n",
            " [[49.         4.       ]\n",
            "  [ 1.         7.2900004]]], shape=(2, 2, 2), dtype=float32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[[ 7.7200003 28.42     ]\n",
            "  [ 1.74      12.36     ]]\n",
            "\n",
            " [[51.        19.4      ]\n",
            "  [ 9.7        9.290001 ]]], shape=(2, 2, 2), dtype=float32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[[ 5.   9.8]\n",
            "  [ 0.6  6.6]]\n",
            "\n",
            " [[14.   4. ]\n",
            "  [ 2.   5.4]]], shape=(2, 2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 6.25      24.01     ]\n",
            "  [ 0.09      10.889999 ]]\n",
            "\n",
            " [[49.         4.       ]\n",
            "  [ 1.         7.2900004]]], shape=(2, 2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 7.7200003 28.42     ]\n",
            "  [ 1.74      12.36     ]]\n",
            "\n",
            " [[51.        19.4      ]\n",
            "  [ 9.7        9.290001 ]]], shape=(2, 2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding largest element in the tensor\n",
        "\n",
        "print(tf.reduce_max(b), '\\n')\n",
        "print(tf.math.argmax(b), '\\n')\n",
        "print(tf.nn.softmax(b), '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC0quz1NOYq6",
        "outputId": "5f3c925e-2b21-4524-b7c8-2ea387200332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(7.0, shape=(), dtype=float32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 0]\n",
            " [1 0]], shape=(2, 2), dtype=int64) \n",
            "\n",
            "tf.Tensor(\n",
            "[[[0.08317269 0.9168273 ]\n",
            "  [0.04742588 0.95257413]]\n",
            "\n",
            " [[0.9933072  0.00669285]\n",
            "  [0.15446527 0.8455348 ]]], shape=(2, 2, 2), dtype=float32) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting np.array into a tensor\n",
        "\n",
        "c = tf.convert_to_tensor(np.array([[2.5, 4.9], [0.3,3.3]]))\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHmpObU2PR_9",
        "outputId": "f1f74165-cbc9-4445-e134-a400abe8f258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2.5 4.9]\n",
            " [0.3 3.3]], shape=(2, 2), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape, rank, axis/dim, size of tensors\n",
        "\n",
        "ZeroTensor = tf.zeros([3,2,4,2]) # here 3: batch, 2:rows, 4:columns, 2:features\n",
        "print(ZeroTensor)\n",
        "\n",
        "print(\"Datatype of every element: \", ZeroTensor.dtype)\n",
        "print(\"dimensions or axes are: \", ZeroTensor.ndim)\n",
        "print(\"Rank is: \", tf.rank(ZeroTensor))\n",
        "print(\"Shape is: \", ZeroTensor.shape)\n",
        "print(\"size is : \", tf.size(ZeroTensor).numpy()) # product of shape elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYdvvtK5QTvK",
        "outputId": "39478a79-472d-41df-df7e-f5c374170d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]]\n",
            "\n",
            "  [[0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]]\n",
            "\n",
            "  [[0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]]\n",
            "\n",
            "  [[0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]\n",
            "   [0. 0.]]]], shape=(3, 2, 4, 2), dtype=float32)\n",
            "Datatype of every element:  <dtype: 'float32'>\n",
            "dimensions or axes are:  4\n",
            "Rank is:  tf.Tensor(4, shape=(), dtype=int32)\n",
            "Shape is:  (3, 2, 4, 2)\n",
            "size is :  48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexing\n",
        "\n",
        "# single axis indexing\n",
        "print(TensorConstant_rank1)\n",
        "print(TensorConstant_rank1[0]) # an element; axis not preserved\n",
        "print(TensorConstant_rank1[2:7]) # a range; axis preserved\n",
        "print(TensorConstant_rank1[2:7:2]) # one other element\n",
        "print(TensorConstant_rank1[::-1]) # reverse\n",
        "\n",
        "# multiaxis indexing\n",
        "print(TensorConstant_rank2[0, :])\n",
        "print(TensorConstant_rank2[: , 1])\n",
        "print(TensorConstant_rank2[1, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--HqaLueSxp7",
        "outputId": "47bc3f66-4e4c-40aa-da52-a720529e803a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2.  4.4 8.2], shape=(3,), dtype=float32)\n",
            "tf.Tensor(2.0, shape=(), dtype=float32)\n",
            "tf.Tensor([8.2], shape=(1,), dtype=float32)\n",
            "tf.Tensor([8.2], shape=(1,), dtype=float32)\n",
            "tf.Tensor([8.2 4.4 2. ], shape=(3,), dtype=float32)\n",
            "tf.Tensor([2.2 3.4], shape=(2,), dtype=float32)\n",
            "tf.Tensor([3.4 6.7], shape=(2,), dtype=float32)\n",
            "tf.Tensor(6.7, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape manipulation\n",
        "\n",
        "print(tf.shape(TensorConstant_rank3))\n",
        "ReshapedTensor = tf.reshape(TensorConstant_rank3, [6,-1])\n",
        "print(ReshapedTensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo5rkUBSVv3M",
        "outputId": "4716b58e-90cd-4069-c874-4d511fa2963b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 2 3], shape=(3,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[2.5 6.8]\n",
            " [1.8 2.5]\n",
            " [6.8 1.8]\n",
            " [2.5 6.8]\n",
            " [1.8 3.3]\n",
            " [6.9 2.1]], shape=(6, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# typecasting\n",
        "\n",
        "Float32Tensor = tf.constant([2.0, 4.4, 8.9])\n",
        "Float16Tensor = tf.cast(Float32Tensor, dtype = tf.float16)\n",
        "print(Float16Tensor, '\\n')\n",
        "UintTensor = tf.cast(Float16Tensor, dtype = tf.uint8)\n",
        "print(UintTensor, '\\n')\n",
        "\n",
        "# Broadcasting\n",
        "\n",
        "print(Float32Tensor * 2) # Basically scalar arthematics operators on all the elements of the tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48jBApk0WwOC",
        "outputId": "2bd8f695-d420-45ef-b21d-b29fc6e9ada5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2.  4.4 8.9], shape=(3,), dtype=float16) \n",
            "\n",
            "tf.Tensor([2 4 8], shape=(3,), dtype=uint8) \n",
            "\n",
            "tf.Tensor([ 4.   8.8 17.8], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Special Tensors\n",
        "\n",
        "# 1) Ragged Tensors = variable number of elements along the axis\n",
        "\n",
        "RaggedList = [[2,4,5],[2,4],[1]]\n",
        "RaggedTensor = tf.ragged.constant(RaggedList)\n",
        "print(RaggedTensor)\n",
        "\n",
        "# 2) Sparse Tensors = sparse data, spaces/gaps in the data\n",
        "\n",
        "SprsTensor = tf.sparse.SparseTensor(indices = [[0,0], [1,2]], values = [1,2], dense_shape = [3,4]) # has 3 rows and 4 columns at (0,0) and (1,2) 1 and 2 is stored, respectively\n",
        "print(SprsTensor)\n",
        "\n",
        "DenseTensor = tf.sparse.to_dense(SprsTensor)\n",
        "print(DenseTensor)\n",
        "\n",
        "# 3) String Vectors = can e split, converted and decoded into unicode, string tensor of numbers can be converted to the int tensor\n",
        "\n",
        "StringList = [\"This\", \"is\", \"a\", \"string\"]\n",
        "StringTensor = tf.constant(StringList)\n",
        "print(StringTensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuLA7ELkYGeN",
        "outputId": "9f81dcd6-e590-4cad-d759-8c878bf3b962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[2, 4, 5], [2, 4], [1]]>\n",
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0]\n",
            " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n",
            "tf.Tensor(\n",
            "[[1 0 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 0]], shape=(3, 4), dtype=int32)\n",
            "tf.Tensor([b'This' b'is' b'a' b'string'], shape=(4,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Everything Variables"
      ],
      "metadata": {
        "id": "I2aFUzxeh07j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor variable\n",
        "\n",
        "MyTensor  = tf.constant([[2.4, 5.6, 2.2],[22.3, 6.7, 8.9]])\n",
        "MyVariable = tf.Variable(MyTensor)\n",
        "print(MyVariable)\n",
        "\n",
        "# could be off all types just like tensors\n",
        "Myvariable = tf.Variable([[True, False],[True, False]])\n",
        "print(Myvariable)\n",
        "\n",
        "# All the arithematic operations like tensors, reshaping creates a new tensor; does not update the pre-existing tensor\n",
        "# No resizing when assign method is used; only same dimension variables can be assigned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8iH8Ro6h0R5",
        "outputId": "975da62a-2c5d-44be-dc5f-d4cf5f15b8dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 2.4,  5.6,  2.2],\n",
            "       [22.3,  6.7,  8.9]], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(2, 2) dtype=bool, numpy=\n",
            "array([[ True, False],\n",
            "       [ True, False]])>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lifecycle, naming and watching\n",
        "\n",
        "a = tf.Variable(MyTensor, name = \"Mark\") # both backed up by the same tensor\n",
        "b = tf.Variable(MyTensor+1,  name = \"Mark\") # broadcasting the scalar addition\n",
        "# element-wise unequal, yet the same name\n",
        "print(a==b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7XtsAzClBIf",
        "outputId": "1118b212-1b65-4468-f60b-b09760cfbbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[False False False]\n",
            " [False False False]], shape=(2, 3), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Placing variables and tensors\n",
        "\n",
        "# most variables are placed in GPU if availible, since it actively chooses fastest device compatible with its datatype\n",
        "# hence use\n",
        "'''\n",
        "with tf.device(\"CPU:0\"):\n",
        "  or\n",
        "with tf.device(\"GPU:0\"):\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r3pnTgvWmDJn",
        "outputId": "d0d8c48a-9fd0-4f4b-8bc3-ca9f45e293c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwith tf.device(\"CPU:0\"):\\n  or\\nwith tf.device(\"GPU:0\"):\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic Differentiation and Gradients"
      ],
      "metadata": {
        "id": "4k0Z9kVFaoL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful for backpropagation algorithms in NN\n",
        "# for automatic differentiation, TensorFlow requires oprations occured in both FP and BP in order to traverse in a reverse direction to compute the gradients\n",
        "# Gradient Tapes API.\n",
        "  # TF keeps the records or \"Tapes\" of operations done in tf.GradientTape() --> it then uses these \"tapes\" to compute gradients by using reverse mode differentiation\n",
        "  # Inputs are in form of tf.Variable\n",
        "\n",
        "newVar = tf.Variable(3.6) # varibale declared\n",
        "with tf.GradientTape() as tape: # recorded operations/functions\n",
        "  y = newVar**2\n",
        "dy_dx = tape.gradient(y, newVar) # calculating the gradient of the target operation (mostly loss) relative to some source (maybe a parameter in model)\n",
        "print(dy_dx.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNZW87jOan73",
        "outputId": "b768f6a1-4840-4c95-eee9-7c9d783d497b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Example 1: using y = (x**2) + x + 5\n",
        "# Example 2: using y = (4(x**3)/3)- x + 2(math.exp(x))\n",
        "X = tf.Variable(3.0) # For now lets keep it scalar\n",
        "with tf.GradientTape(persistent=True) as Tape: # can calculate multiple gradients\n",
        "  Y = (X**2) + X + 5\n",
        "  Z = ((4/3) * (X**3)) - X - (2 * math.exp(X))\n",
        "  Q = 2 * ((1/(X ** 1/2))) + (X ** 1/2)\n",
        "ExGrad = Tape.gradient(Y, X)\n",
        "ExGrad1 = Tape.gradient(Z, X)\n",
        "ExGrad2 = Tape.gradient(Q, X)\n",
        "\n",
        "print(ExGrad2.numpy())\n",
        "\n",
        "# footnote: if you are dealing with tensor (not scalar),\n",
        "#           then use differentiable variables in a dictionary and then calculate the gradient\n",
        "#           make sure the declaration name and the dictionary key is same!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj5vzC4VoJzD",
        "outputId": "185e5885-f2ea-4fa6-e705-6fbe24a64ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.055555552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using tf.GradientTape() over any tensor; but scalar\n",
        "\n",
        "Weights = tf.Variable(tf.random.normal(shape = (3,2)), name = 'w')\n",
        "Biases = tf.Variable(tf.zeros(shape = (2, ), dtype = tf.float32), name = 'b')\n",
        "xVar = [[3.0,4.6,9.2]]\n",
        "\n",
        "with tf.GradientTape() as Tape:\n",
        "  y = (xVar @ Weights) + Biases\n",
        "  Loss = tf.reduce_mean(y**2) # tf.reduce_mean(inputTensor, axis = 0 by column or 1 by row) calculates the mean via dimensions\n",
        "\n",
        "'''\n",
        "passing explicitly\n",
        "[dl_dw, dl_db] = Tape.gradient(Loss, [Weights, Biases])\n",
        "print([dl_dw, dl_db]) # dl_dw will have same shape as Weights (applies for all the gradients)\n",
        "\n",
        "OR\n",
        "\n",
        "passing via dictionary\n",
        "'''\n",
        "Variables = {\n",
        "    'w' : Weights,\n",
        "    'b' : Biases\n",
        "}\n",
        "\n",
        "Grad = Tape.gradient(Loss, Variables)\n",
        "print(Grad['b'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud0S4yLRe2SE",
        "outputId": "fe1d9840-bc3b-4add-f54d-ab66d9b0377e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([-13.13342   11.921021], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradients w. r. t. models\n",
        "\n",
        "Layer = tf.keras.layers.Dense(2, activation=\"relu\")\n",
        "xVar = tf.constant([[2.3, 5.6, 7.8]]) # Declare inputs after declaring the layers\n",
        "\n",
        "with tf.GradientTape() as Tape:\n",
        "  # forwards pass\n",
        "  y = Layer(xVar)\n",
        "  Loss = tf.reduce_mean(y**2)\n",
        "\n",
        "# Backwards pass\n",
        "Grad = Tape.gradient(Loss, Layer.trainable_variables)\n",
        "\n",
        "for ele1, ele2 in zip(Layer.trainable_variables, Grad): # zip funtion zips the sequential elements in a tuple.\n",
        "  print(f\"{ele1.name}, shape:  {ele2.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYNBhSrel_Un",
        "outputId": "edb07971-3557-4aa8-e8a2-d2d4697318dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kernel, shape:  (3, 2)\n",
            "bias, shape:  (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Controlling the tape's behaviour (What it watches)\n",
        "\n",
        "'''\n",
        "default behaviour is to record all the operations, why?, because:\n",
        "  - tape needs to know what to record\n",
        "  - tape holds the reference to intermediate outputs (to avoid recording of unnecessary operations)\n",
        "  - basic case tape does: calculate the gradient of loss with respect to one of the trainable variable_accessed\n",
        "'''\n",
        "\n",
        "TrainableVar = tf.Variable(4.0)\n",
        "Non_TrainableVar1 = tf.Variable(3.4, trainable = False)\n",
        "Non_TrainableVar2 = tf.Variable(2.3) + 1.0\n",
        "Non_TrainableVar3 = tf.constant(4.0)\n",
        "\n",
        "with tf.GradientTape() as Tape:\n",
        "  y = (TrainableVar **2) + (Non_TrainableVar1 **2) + (Non_TrainableVar2 **2) + (Non_TrainableVar3 **2)\n",
        "\n",
        "Grad = Tape.gradient(y, [TrainableVar, Non_TrainableVar1, Non_TrainableVar2, Non_TrainableVar3])\n",
        "print(Grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAMlNDQwt2CK",
        "outputId": "240bb2b8-3e16-42b5-ee6d-1b98d5747fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>, None, None, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.GradientTape() by default watches all the variables; you can customise it!\n",
        "\n",
        "x0 = tf.Variable(3.5)\n",
        "x1 = tf.Variable(4.9)\n",
        "\n",
        "with tf.GradientTape(watch_accessed_variables=False) as Tape: # Default behaviour is stopped\n",
        "  Tape.watch(x1) # Specific gradient will be calculated for x1 only since its the only one under the watch\n",
        "  y0 = tf.math.sin(x0)\n",
        "  y1 = tf.nn.softplus(x1) # smooth approximation of relu, only takes posiitve values in consideration\n",
        "  y = y0 + y1\n",
        "  ys = tf.reduce_sum(y) # no MSE calculated - no large errors and no need to penalise them\n",
        "\n",
        "Grad = Tape.gradient(ys, [x0, x1])\n",
        "print(Grad[0], '\\n', Grad[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktqHCrRx2pgZ",
        "outputId": "57b50053-a632-4bdb-f374-dd1748f6888d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None \n",
            " tf.Tensor(0.9926085, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Intermediate results\n",
        "\n",
        "# you can watch and request gradient outputs for intermediate values calculated inside the tape\n",
        "\n",
        "x0 = tf.constant(3.0)\n",
        "\n",
        "with tf.GradientTape() as Tape:\n",
        "  Tape.watch(x0)\n",
        "  y = x0*x0\n",
        "  z = y*y\n",
        "\n",
        "# Calculating z with respect to y\n",
        "Grad = Tape.gradient(z, y)\n",
        "print(Grad)"
      ],
      "metadata": {
        "id": "p_gGvhVFCuJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4adda8-abf7-4e7f-e4f6-03e2697f48d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(18.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# once you call Tape.gradient(source, difffactor),resources held by tape are gone.\n",
        "# to calculate multiple gradients in one block use this\n",
        "\n",
        "x0 = tf.constant([1.0, 3.0])\n",
        "with tf.GradientTape(persistent = True) as Tape: # use persistent as True\n",
        "  Tape.watch(x0)\n",
        "  y = x0*x0\n",
        "  z = y*y\n",
        "\n",
        "Grad1 = Tape.gradient(z, x0)\n",
        "Grad2 = Tape.gradient(y, x0)\n",
        "\n",
        "print(Grad1, '\\n', Grad2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5Xc-SnaI0ug",
        "outputId": "94efba94-9b0d-4e4f-a4dc-f39694ba5b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([  4. 108.], shape=(2,), dtype=float32) \n",
            " tf.Tensor([2. 6.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tape's gone\n",
        "\n",
        "del Tape"
      ],
      "metadata": {
        "id": "l2_3bQ0wSfim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Notes"
      ],
      "metadata": {
        "id": "Yrr02tpYhOt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# at persistent = True all the intermediate calculations are stored, hence higher memory usage\n",
        "# when the gradient of multiple targets are requested\n",
        "\n",
        "x0 = tf.Variable(2.3)\n",
        "with tf.GradientTape(persistent = True) as Tape:\n",
        "  y0 = x0 ** 2\n",
        "  y1 = 1/x0\n",
        "\n",
        "print(Tape.gradient(y0,x0))\n",
        "print(Tape.gradient(y1,x0))\n",
        "\n",
        "# gradients of the sum OR sum of the gradients\n",
        "print(Tape.gradient({'y0': y0, 'y1': y1},x0))\n",
        "# gradient of sum is calculated for non-scalars y = x * [3.4, 5.7] and x is variable with 0 rank\n",
        "\n",
        "# cases when gradient returns None:\n",
        "'''\n",
        "- when target is not connected to the source\n",
        "- doing calculation outside tensorflow\n",
        "- replacing variable with a tensor\n",
        "- taking gradients as int or str\n",
        "- stateful object's current states are seen not the history lead to it\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "KgoXTarhhRoB",
        "outputId": "8cd3f260-f11b-44c8-923d-314d536e5090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(4.6, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.18903592, shape=(), dtype=float32)\n",
            "tf.Tensor(4.410964, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n- when target is not connected to the source\\n- doing calculation outside tensorflow\\n- replacing variable with a tensor\\n- taking gradients as int or str\\n- stateful object's current states are seen not the history lead to it\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sometimes it is better to return zeros instead of None\n",
        "\n",
        "x = tf.Variable([2.2, 2.2])\n",
        "y = tf.Variable(3, )\n",
        "with tf.GradientTape() as Tape:\n",
        "  z = y ** 2\n",
        "print(Tape.gradient(z, x, unconnected_gradients= tf.UnconnectedGradients.ZERO))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeOsUl9OzoPQ",
        "outputId": "0d741beb-1249-46c4-b153-3519c01be390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphs and Functions"
      ],
      "metadata": {
        "id": "bI_YFFmm8qvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what are the \"graphs\"?\n",
        "\n",
        "'''\n",
        "- Eager execution: line-by-line in Python; Graph execution: in type of graph \"tf.Graph\"\n",
        "- tf.graph = has operations (units of computation) and tensor objects (units of data that flow within these operations)\n",
        "- You can visualise these graphs via TensorBoard; and can be used in environments without python interpreter (mobile apps, embedded devices, backend servers)\n",
        "- saving format : \"Saved models\"; subsequent exporting via Python\n",
        "- extremly useful, fast, ran in parallel and run efficiently on multiple devices.\n",
        "'''\n",
        "\n",
        "# import important libraries\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "lGgDlLkm84c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating functions\n",
        "\n",
        "# define a simple python function\n",
        "def RegFunction(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# Polymorphic function creation using tf.function\n",
        "GraphFunction = tf.function(RegFunction)\n",
        "\n",
        "# input tensors\n",
        "x1 = tf.constant([[1.0, 2.0]])\n",
        "y1 = tf.constant([[2.0], [4.0]])\n",
        "b1 = tf.constant(4.0)\n",
        "\n",
        "# call original function\n",
        "OGcall = RegFunction(x1, y1, b1).numpy()\n",
        "# TF graph function call\n",
        "GraphCall = GraphFunction(x1, y1, b1).numpy()\n",
        "assert(OGcall == GraphCall) # if condition is False; assertion error is thrown\n"
      ],
      "metadata": {
        "id": "bQc0GMws_h7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.function applies to a function and all other functions it calls\n",
        "\n",
        "def InnerFunction(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x+b\n",
        "  return x\n",
        "\n",
        "@tf.function # wrapper/decorator; a polymorphic function that morphs the normal functions\n",
        "def OuterFunction(x):\n",
        "  y = tf.constant([[2.0], [4.0]])\n",
        "  b = tf.constant(4.0)\n",
        "  return InnerFunction(x, y, b)\n",
        "\n",
        "# calling out the functions is \"The first step of graph creation\"\n",
        "OuterFunction(tf.constant([[1.3, 4.5]])).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Wpo67Akxk3b",
        "outputId": "5c778908-1102-42ca-bb09-814e88877ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24.6]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting python functions into graphs\n",
        "\n",
        "'''\n",
        "Contains both tf.Operations and python code logic\n",
        "so tf.function library called \"tf.autograph\" converts python code into graph-generating code\n",
        "'''\n",
        "\n",
        "def SimpleReLu(x):\n",
        "  if tf.greater(x,0):\n",
        "    return x\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "TFSimpleReLu = tf.function(SimpleReLu)\n",
        "\n",
        "print(\"First branch, with graph: \", TFSimpleReLu(tf.constant(1).numpy()))\n",
        "print(\"Second branch, with graph: \", TFSimpleReLu(tf.constant(-1).numpy()))\n",
        "\n",
        "# Graph-generating output\n",
        "#print(tf.autograph.to_code(SimpleReLu))\n"
      ],
      "metadata": {
        "id": "8UudnwK21Kuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc919877-b02c-415f-f516-0c9a0b602564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First branch, with graph:  tf.Tensor(1, shape=(), dtype=int32)\n",
            "Second branch, with graph:  tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the graph\n",
        "print(TFSimpleReLu.get_concrete_function(tf.constant(2)).graph.as_graph_def())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdk4f36U4Vuw",
        "outputId": "df58b7f1-744d-43a4-eac1-c91c30d969d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node {\n",
            "  name: \"x\"\n",
            "  op: \"Placeholder\"\n",
            "  attr {\n",
            "    key: \"shape\"\n",
            "    value {\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"dtype\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"_user_specified_name\"\n",
            "    value {\n",
            "      s: \"x\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"Greater/y\"\n",
            "  op: \"Const\"\n",
            "  attr {\n",
            "    key: \"value\"\n",
            "    value {\n",
            "      tensor {\n",
            "        dtype: DT_INT32\n",
            "        tensor_shape {\n",
            "        }\n",
            "        int_val: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"dtype\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"Greater\"\n",
            "  op: \"Greater\"\n",
            "  input: \"x\"\n",
            "  input: \"Greater/y\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"cond\"\n",
            "  op: \"StatelessIf\"\n",
            "  input: \"Greater\"\n",
            "  input: \"x\"\n",
            "  attr {\n",
            "    key: \"then_branch\"\n",
            "    value {\n",
            "      func {\n",
            "        name: \"cond_true_562\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"output_shapes\"\n",
            "    value {\n",
            "      list {\n",
            "        shape {\n",
            "        }\n",
            "        shape {\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"else_branch\"\n",
            "    value {\n",
            "      func {\n",
            "        name: \"cond_false_563\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"_read_only_resource_inputs\"\n",
            "    value {\n",
            "      list {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"_lower_using_switch_merge\"\n",
            "    value {\n",
            "      b: true\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"Tout\"\n",
            "    value {\n",
            "      list {\n",
            "        type: DT_BOOL\n",
            "        type: DT_INT32\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"Tin\"\n",
            "    value {\n",
            "      list {\n",
            "        type: DT_INT32\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"Tcond\"\n",
            "    value {\n",
            "      type: DT_BOOL\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"cond/Identity\"\n",
            "  op: \"Identity\"\n",
            "  input: \"cond\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_BOOL\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"cond/Identity_1\"\n",
            "  op: \"Identity\"\n",
            "  input: \"cond:1\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"Identity\"\n",
            "  op: \"Identity\"\n",
            "  input: \"cond/Identity_1\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            "library {\n",
            "  function {\n",
            "    signature {\n",
            "      name: \"cond_false_563\"\n",
            "      input_arg {\n",
            "        name: \"cond_placeholder\"\n",
            "        type: DT_INT32\n",
            "      }\n",
            "      output_arg {\n",
            "        name: \"cond_identity\"\n",
            "        type: DT_BOOL\n",
            "      }\n",
            "      output_arg {\n",
            "        name: \"cond_identity_1\"\n",
            "        type: DT_INT32\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_BOOL\n",
            "            tensor_shape {\n",
            "            }\n",
            "            bool_val: true\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const_1\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_BOOL\n",
            "            tensor_shape {\n",
            "            }\n",
            "            bool_val: true\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const_2\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_INT32\n",
            "            tensor_shape {\n",
            "            }\n",
            "            int_val: 0\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_INT32\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const_3\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_BOOL\n",
            "            tensor_shape {\n",
            "            }\n",
            "            bool_val: true\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Identity\"\n",
            "      op: \"Identity\"\n",
            "      input: \"cond/Const_3:output:0\"\n",
            "      attr {\n",
            "        key: \"T\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const_4\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_INT32\n",
            "            tensor_shape {\n",
            "            }\n",
            "            int_val: 0\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_INT32\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Identity_1\"\n",
            "      op: \"Identity\"\n",
            "      input: \"cond/Const_4:output:0\"\n",
            "      attr {\n",
            "        key: \"T\"\n",
            "        value {\n",
            "          type: DT_INT32\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    ret {\n",
            "      key: \"cond_identity\"\n",
            "      value: \"cond/Identity:output:0\"\n",
            "    }\n",
            "    ret {\n",
            "      key: \"cond_identity_1\"\n",
            "      value: \"cond/Identity_1:output:0\"\n",
            "    }\n",
            "    attr {\n",
            "      key: \"_construction_context\"\n",
            "      value {\n",
            "        s: \"kEagerRuntime\"\n",
            "      }\n",
            "    }\n",
            "    arg_attr {\n",
            "      key: 0\n",
            "      value {\n",
            "        attr {\n",
            "          key: \"_output_shapes\"\n",
            "          value {\n",
            "            list {\n",
            "              shape {\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  function {\n",
            "    signature {\n",
            "      name: \"cond_true_562\"\n",
            "      input_arg {\n",
            "        name: \"cond_identity_1_x\"\n",
            "        type: DT_INT32\n",
            "      }\n",
            "      output_arg {\n",
            "        name: \"cond_identity\"\n",
            "        type: DT_BOOL\n",
            "      }\n",
            "      output_arg {\n",
            "        name: \"cond_identity_1\"\n",
            "        type: DT_INT32\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_BOOL\n",
            "            tensor_shape {\n",
            "            }\n",
            "            bool_val: true\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Identity\"\n",
            "      op: \"Identity\"\n",
            "      input: \"cond/Const:output:0\"\n",
            "      attr {\n",
            "        key: \"T\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Identity_1\"\n",
            "      op: \"Identity\"\n",
            "      input: \"cond_identity_1_x\"\n",
            "      attr {\n",
            "        key: \"T\"\n",
            "        value {\n",
            "          type: DT_INT32\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    ret {\n",
            "      key: \"cond_identity\"\n",
            "      value: \"cond/Identity:output:0\"\n",
            "    }\n",
            "    ret {\n",
            "      key: \"cond_identity_1\"\n",
            "      value: \"cond/Identity_1:output:0\"\n",
            "    }\n",
            "    attr {\n",
            "      key: \"_construction_context\"\n",
            "      value {\n",
            "        s: \"kEagerRuntime\"\n",
            "      }\n",
            "    }\n",
            "    arg_attr {\n",
            "      key: 0\n",
            "      value {\n",
            "        attr {\n",
            "          key: \"_user_specified_name\"\n",
            "          value {\n",
            "            s: \"x\"\n",
            "          }\n",
            "        }\n",
            "        attr {\n",
            "          key: \"_output_shapes\"\n",
            "          value {\n",
            "            list {\n",
            "              shape {\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "versions {\n",
            "  producer: 2129\n",
            "  min_consumer: 12\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Polymorphism: one tf.function -- many graphs\n",
        "\n",
        "# tf.function creates different output graph with different datatype of input argument\n",
        "\n",
        "@tf.function\n",
        "def ReLu(x):\n",
        "  return tf.maximum(0.0, x)\n",
        "\n",
        "print(ReLu(tf.constant(2.3)))\n",
        "print(ReLu(tf.constant([[2.3,5.6],[8.6,2.6]])))\n",
        "# if alrady the same type id called, then no graphs are created again\n",
        "print(ReLu(tf.constant(2.3))) # no graph for this is created cuz already encountered it!\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbO055KM5sPM",
        "outputId": "40e5c1fc-81d8-4bc2-b055-461cb68dc569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(2.3, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[2.3 5.6]\n",
            " [8.6 2.6]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(2.3, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# actual use case tf.function\n",
        "\n",
        "# define function\n",
        "@tf.function\n",
        "def MSE(y0, y1):\n",
        "  SqDiff = tf.pow(y0-y1, 2)\n",
        "  return tf.reduce_mean(SqDiff)\n",
        "\n",
        "# Getting tensor inputs\n",
        "Y0 = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "Y1 = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "print(MSE(Y0, Y1))\n",
        "\n",
        "# Making eager execution\n",
        "tf.config.run_functions_eagerly(True)\n",
        "print(MSE(Y0, Y1))\n",
        "\n",
        "# stopping eager execution\n",
        "tf.config.run_functions_eagerly(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVzrk9IUCrwm",
        "outputId": "d062725a-2628-46d1-c98e-7afd5786fd09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tracing:- creation of the graph in the order of execution\n",
        "#         - captures operations into the graph\n",
        "\n",
        "@tf.function\n",
        "def MSE(y0, y1):\n",
        "  print(\"allo\")\n",
        "  SqDiff = tf.pow(y0-y1, 2)\n",
        "  return tf.reduce_mean(SqDiff)\n",
        "\n",
        "CallFunc = MSE(Y0, Y1)\n",
        "CallFunc = MSE(Y0, Y1)\n",
        "CallFunc = MSE(Y0, Y1)\n",
        "\n",
        "'''\n",
        "explaination:\n",
        "- print function is not captured in the graph.\n",
        "- tf.function ran it once, saw it wasn't a graph generating operation, never executed again\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "WRgkgibuJW10",
        "outputId": "cde6ac2f-8769-4da2-f086-46918c6c74fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allo\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nexplaination:\\n- print function is not captured in the graph.\\n- tf.function ran it once, saw it wasn't a graph generating operation, never executed again\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call them eagerly\n",
        "tf.config.run_functions_eagerly(True)\n",
        "CallFunc = MSE (Y0, Y1)\n",
        "CallFunc = MSE (Y0, Y1)\n",
        "CallFunc = MSE (Y0, Y1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk8BtFF_L8pS",
        "outputId": "6e114f58-d6ee-4f73-9fd9-f7c3fd4d8207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allo\n",
            "allo\n",
            "allo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-strict execution:- necessary operations (operations which produce observable effects) are executed\n",
        "# opposite of the eager execution\n",
        "\n",
        "def UnseenEagerFunction(x):\n",
        "  tf.gather(x, [1])\n",
        "  return x # ignored previous operation\n",
        "\n",
        "try:\n",
        "  print(UnseenEagerFunction(tf.constant([0.0])))\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(\"Error\")\n",
        "\n",
        "# error is raised since it is \"Eager operation\"; no error if it was graph constructing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EBpJfKkYOF3",
        "outputId": "a4b66fb9-6dff-40ee-c267-316e4dda8b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Everything Models, Layers and Modules"
      ],
      "metadata": {
        "id": "goEdAPs0eV1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TensorFlow Models**: creation, loading, execution and saving"
      ],
      "metadata": {
        "id": "zvw7RmufmVIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import important modules\n",
        "\n",
        "import keras\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "mzKmKbgHea7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First clear up the basics of OOPs\n",
        "\n",
        "class ModuleFunctionality:\n",
        "  def __init__(self): # self instance attributes\n",
        "    self.cardinal1 = tf.Variable([[1.2, 2.3]])\n",
        "    self.cardinal2 = tf.Variable([[8.2, 2.9]])\n",
        "    self.cardinal3 = tf.Variable([[9.2, 5.3]])\n",
        "\n",
        "  def CallSuperior(self):\n",
        "    return (self.cardinal1 + self.cardinal2) * self.cardinal3\n",
        "\n",
        "\n",
        "class ModuleFunctionality2(ModuleFunctionality):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  def CallSuperior2(self):\n",
        "    return (super().CallSuperior())\n",
        "\n",
        "ModularityObject = ModuleFunctionality2()\n",
        "print(ModularityObject.CallSuperior().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV5FbkwbekZ-",
        "outputId": "4b2b278a-1435-4dd1-dceb-e92dbdfc2060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[86.479996 27.56    ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us experiment with the super keyword and hierarchial relationship of classes\n",
        "\n",
        "class classCodec:\n",
        "  def __init__(self):\n",
        "    self.codec1 = tf.Variable([[2.5, 4.6]])\n",
        "    self.codec2 = tf.Variable([[0.5, 4.0]])\n",
        "\n",
        "  def CodecOp(self):\n",
        "    return (self.codec1 + self.codec2)\n",
        "\n",
        "ObjCodec = classCodec()\n",
        "print(ObjCodec.CodecOp().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRdy2j9FvMSr",
        "outputId": "564712ec-41ce-42f5-9d8e-5bbdb92f6ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.  8.6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of simple module\n",
        "\n",
        "'''\n",
        "modules/extensions are deep learning terminologies of Obj in TF\n",
        "can store the function, input or any object\n",
        "use case:- creation of FCL in DL model is done in a module; custom module is required\n",
        "'''\n",
        "\n",
        "class SimpleModule(tf.Module):\n",
        "  def __init__(self, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.TrainVar = tf.Variable(3.7, name = \"Trainable variable in this module\")\n",
        "    self.UnTrainVar = tf.Variable(7.8, trainable = False, name = \"Non-trainable variable in this module\")\n",
        "# can toggle trainability; especially during fine tuning, freezing layer and dropout\n",
        "  def __call__(self, xinp): # another parameter;\n",
        "                            # mention attribute while instantiating the object\n",
        "\n",
        "    return self.TrainVar * xinp + self.UnTrainVar\n",
        "\n",
        "SimpleModuleObject = SimpleModule(name = \"CreationFirst\")\n",
        "print(SimpleModuleObject(tf.constant(0.9)).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e80WQ6QyznsZ",
        "outputId": "208995af-ca6b-4064-b747-6395ca3e9959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing trainable variables\n",
        "\n",
        "print(SimpleModuleObject.trainable_variables) # mention the created object not the class design"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtOEF8kKMyY6",
        "outputId": "f5d8e334-d418-4018-c5ab-c162ee55eccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Variable 'Trainable variable in this module:0' shape=() dtype=float32, numpy=3.700000047683716>,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating and calling a bilinear dense layer model out of modules\n",
        "\n",
        "class Dense(tf.Module):\n",
        "  def __init__(self, Inpfeat, Outfeat, name = None): # input and output features\n",
        "    super().__init__(name = name)\n",
        "    self.W = tf.Variable(tf.random.normal([Inpfeat, Outfeat]), name = \"W\")\n",
        "    self.B = tf.Variable(tf.zeros([Outfeat]), name = \"B\")\n",
        "# forward pass:- calculating the activation using activation function\n",
        "  def __call__(self, X0):\n",
        "    Y = tf.matmul(X0, self.W) + self.B\n",
        "    return tf.nn.relu(Y)\n",
        "\n",
        "class Seqlayer(tf.Module): # Creating the sequential layer\n",
        "  def __init__(self, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.Denselayer1 = Dense(Inpfeat = 3, Outfeat = 3)\n",
        "    self.Denselayer2 = Dense(Inpfeat = 3, Outfeat = 2)\n",
        "\n",
        "  def __call__(self, X0):\n",
        "    X0 = self.Denselayer1(X0)\n",
        "    return self.Denselayer2(X0)\n",
        "\n",
        "# creating object\n",
        "Model1 = Seqlayer(name = \"The_Model\") # the name must be a valdi identifier\n",
        "print(f\"These are the model results: {Model1(tf.constant([[2.4, 2.7, 3.6]]))}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LjZj-LI22L5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4066c564-d6c7-4c68-8263-33c011da9732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These are the model results: [[0.        0.3901045]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the submodules\n",
        "print(Model1.submodules)\n",
        "\n",
        "# printing all of the variables\n",
        "[print(i, '\\n') for i in Model1.variables]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9nVIKQOc28m",
        "outputId": "218b53a3-b8ba-47fb-a738-ed660967178e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<__main__.Dense object at 0x7f18759667e0>, <__main__.Dense object at 0x7f1875966060>)\n",
            "<tf.Variable 'B:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)> \n",
            "\n",
            "<tf.Variable 'W:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.655239  , -0.7906698 ,  0.00676947],\n",
            "       [-0.547157  , -0.5569847 , -0.11925808],\n",
            "       [ 0.34196427,  0.3164401 ,  0.07018065]], dtype=float32)> \n",
            "\n",
            "<tf.Variable 'B:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)> \n",
            "\n",
            "<tf.Variable 'W:0' shape=(3, 2) dtype=float32, numpy=\n",
            "array([[-1.3128257 ,  0.29412523],\n",
            "       [-0.58154505,  0.7054874 ],\n",
            "       [-1.3829682 , -0.23948003]], dtype=float32)> \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: creating custom module\n",
        "\n",
        "\n",
        "\n",
        "# it sets the parameters up as instance attributes\n",
        "# it calculates the output as instance method\n",
        "class DenseCalc(tf.Module):\n",
        "  def __init__(self, In, Out, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.W = tf.Variable(tf.random.normal([In, Out], name = 'W'))\n",
        "    self.B = tf.zeros([Out], name = \"B\")\n",
        "\n",
        "  def CalcAct(self, x):\n",
        "    Y = (self.W * x) + self.B\n",
        "    return tf.nn.relu(Y)\n",
        "\n",
        "MyObj = DenseCalc(1, 3) # not calling any method; just declaring instance attributes\n",
        "# no error\n",
        "\n",
        "# call the method with suitable arguments\n",
        "print(MyObj.CalcAct(tf.constant([[2.3, 4.5, 3.3]])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwmfpzowTrEU",
        "outputId": "a86f914b-cb42-4d29-f2cd-122961fd3d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[1.2862445 0.        0.4753863]], shape=(1, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating variables in the first call and Only specifying the number of output features\n",
        "\n",
        "class Setup(tf.Module):\n",
        "  def __init__(self, Out, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.isbuild = False\n",
        "    self.Out = Out\n",
        "  def __call__(self, x): # __call__ is important\n",
        "    if not self.isbuild:\n",
        "      self.w = tf.Variable(tf.random.normal([x.shape[-1], self.Out]), name = 'w')\n",
        "      self.b = tf.Variable(tf.zeros([self.Out]), name = 'b')\n",
        "      self.isbuild = True\n",
        "\n",
        "    Y = tf.matmul(x, self.w) + self.b\n",
        "    return tf.nn.relu(Y)\n",
        "\n",
        "class FinalLayers(tf.Module):\n",
        "  def __init__(self, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.Dense1 = Setup(Out=3)\n",
        "    self.Dense2 = Setup(Out=2)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.Dense1(x)\n",
        "    return self.Dense2(x)\n",
        "\n",
        "\n",
        "DemoObj = FinalLayers(name = \"trail\")\n",
        "print(DemoObj(tf.constant([[2.3, 2.3, 4.4]])))\n",
        "\n",
        "# footnote:- here the __call__ method makes the instance attributes behave like a function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqmfip4iiD8U",
        "outputId": "802c86ff-10f9-4766-f5a7-b692f544a4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.         0.15773125]], shape=(1, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Functions\n",
        "\n",
        "'''\n",
        "- The graphs save functions and ops.\n",
        "- TF is capable of running models without og python objects\n",
        "- use graphs to tell TF to do operations in og python, without its og code\n",
        "'''\n",
        "\n",
        "\n",
        "class FinalLayers(tf.Module):\n",
        "  def __init__(self, name = None):\n",
        "    super().__init__(name = name)\n",
        "    self.Dense1 = Setup(Out=3)\n",
        "    self.Dense2 = Setup(Out=2)\n",
        "\n",
        "  @tf.function # decorator for making the base code operations as a graph\n",
        "  def __call__(self, x):\n",
        "    x = self.Dense1(x)\n",
        "    return self.Dense2(x)\n",
        "\n",
        "\n",
        "DemoObj = FinalLayers(name = \"trail\")\n",
        "\n",
        "# footnote:- works same as before;\n",
        "# each signature is passed in function --> separate graph is created\n",
        "\n",
        "print(DemoObj(tf.constant([[2.3, 2.3, 4.4]])))\n",
        "print(DemoObj(tf.constant([[[2.3, 2.3, 4.4], [2.3, 2.3, 4.4]]])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdF5ik0CWHCq",
        "outputId": "27375a8a-79ea-417e-e45c-917016fb9b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.7302979  0.17195863]], shape=(1, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.7302979  0.17195863]\n",
            "  [0.7302979  0.17195863]]], shape=(1, 2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the models\n",
        "\n",
        "'''\n",
        "- best for sharing completely trained models\n",
        "- has all the collection of weights and fucntions\n",
        "- creates a file named .pb (protocol buffer), describing the functional tf.Graph\n",
        "'''\n",
        "\n",
        "tf.saved_model.save(DemoObj, \"saved_model\")\n"
      ],
      "metadata": {
        "id": "HVWpZ_JmjR-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model\n",
        "\n",
        "LoadMod = tf.saved_model.load(\"saved_model\")"
      ],
      "metadata": {
        "id": "3Ovnxst8lYlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restoring and using model\n",
        "\n",
        "print(DemoObj(tf.constant([[2.0,2.0,2.0]]))) # calling the fucntion normally\n",
        "\n",
        "# Footnote:- input signatures defined cant be changed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbuUy0CjlgPU",
        "outputId": "2f702797-413f-4d2e-ca13-08b35ef6596a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[3.7339342  0.87920576]], shape=(1, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Keras Models**: creation, loading, execution and saving"
      ],
      "metadata": {
        "id": "axB2bURhmjpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learn how keras uses tf.Module and is much more efficient\n",
        "import keras"
      ],
      "metadata": {
        "id": "knBL0E-nmmGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras Layers\n",
        "\n",
        "'''\n",
        "- tf.keras.layers.Layer:- base class for all keras layer; inherits form tf.Module!\n",
        "- just change tf.Module to tf.keras.layers.Layer and __call__ to call\n",
        "- intialise with keywords args to keep other many kera layer arguments\n",
        "'''\n",
        "\n",
        "# Method 1 :- with specifying both input signatures\n",
        "\n",
        "class DenseCalc(tf.keras.layers.Layer):\n",
        "  def __init__(self, In, Out, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.weight = tf.Variable(tf.random.normal([In, Out]), name = 'w')\n",
        "    self.bias = tf.Variable(tf.zeros([Out]), name = 'b')\n",
        "\n",
        "  def call(self, x):\n",
        "    Y = tf.matmul(x, self.weight) + self.bias\n",
        "    return tf.nn.relu(Y)\n",
        "\n",
        "OnelayerModel = DenseCalc(name = \"One_Layer_Model\", In = 3, Out = 3 )\n",
        "\n",
        "print(OnelayerModel(tf.constant([[2.0,2.0,2.0]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uATXwUm3mydG",
        "outputId": "2a3e98cc-37e2-4dad-d5aa-ef14d8d0af7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.        1.0731897 2.297532 ]], shape=(1, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 2 :- with specifying only one signature (Number of Output Features)\n",
        "\n",
        "class DenseCalc(tf.keras.layers.Layer):\n",
        "  def __init__(self, Out, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.Out = Out\n",
        "\n",
        "  def build(self, In): # build and call are reserved keywords\n",
        "    self.w =  tf.Variable(tf.random.normal([In[-1], self.Out]), name = 'w')\n",
        "    self.b = tf.Variable(tf.zeros([self.Out]), name = 'b')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    Y = tf.matmul(inputs, self.w) + self.b\n",
        "    return tf.nn.relu(Y)\n",
        "\n",
        "FlexibleModel = DenseCalc(name = \"Flexible_Model\", Out = 3)\n",
        "print(FlexibleModel(tf.constant([[2.0,2.0,2.0]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOm40uq_qspm",
        "outputId": "2575c334-48a6-4493-f745-d5d239b04411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[5.141865  1.9790626 0.       ]], shape=(1, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras models\n",
        "\n",
        "'''\n",
        "- Basically nested keras layers or a class named \"tf.keras.Model\" (inherits from tf.keras.layers.Layer)\n",
        "- this class can also be nested\n",
        "- better functionality and performance with ability to train it on multiple machines\n",
        "'''\n",
        "\n",
        "# describing the architecture\n",
        "\n",
        "@keras.saving.register_keras_serializable() # decorator for custom keras obj (mdoel, act, layer); correct saving and storage\n",
        "class ArchDes(tf.keras.Model):\n",
        "  def __init__(self, name = None, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.DL1 = DenseCalc(Out = 3)\n",
        "    self.DL2 = DenseCalc(Out = 2)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    inputs = self.DL1(inputs)\n",
        "    return self.DL2(inputs)\n",
        "\n",
        "KerasSimpleModel = ArchDes(name = \"First_keras_model\")\n",
        "print(KerasSimpleModel(tf.constant([[2.0, 4.6, 7.9]])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEAmOzpV3DCo",
        "outputId": "adcd78db-20ed-4eb5-84b1-288a96600cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "\n",
        "KerasSimpleModel.save(\"keras_model.keras\")"
      ],
      "metadata": {
        "id": "Knt3X5fRJPwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loadign the model\n",
        "\n",
        "NewModel = tf.keras.models.load_model(\"keras_model.keras\")\n"
      ],
      "metadata": {
        "id": "TZy9-sycJTkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restoring and Using the model\n",
        "\n",
        "print(NewModel(tf.constant([[2.0, 2.9, 9.5]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmU_CN75Kw9v",
        "outputId": "7ef7a928-581e-40d5-b8c1-a2bea3c4eb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.       8.692691]], shape=(1, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loops"
      ],
      "metadata": {
        "id": "1QEbECkDLb3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "colours = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "# prop_cycle to change the colour of the plot"
      ],
      "metadata": {
        "id": "wT6fA8kSLZOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Approaching ML problems\n",
        "\n",
        "'''\n",
        "get data --> define model --> define L --> calculate activation and L -->\n",
        "calculate gradient for L --> fit the gradients for all the paras using optimisers\n",
        "--> evaluate the results\n",
        "'''\n",
        "\n",
        "# Problem 1:- Simple Linear Regression :- Input/output/target :- everythings a tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "dGLdjWDsbFOn",
        "outputId": "5aa036e7-853f-4a33-afe9-2aa6ef116188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nget data --> define model --> define L --> calculate activation and L -->\\ncalculate gradient for L --> fit the gradients for all the paras using optimisers\\n--> evaluate the results\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating supervised learning data with gaussian noise\n",
        "\n",
        "ActualW = 5.0\n",
        "ActualB = 3.0 # actual parameters\n",
        "\n",
        "NumExamples = 200\n",
        "\n",
        "# Now we will generate x first (vector of 200 random evenly spaced values from -2 to 2)\n",
        "X = tf.linspace(-2, 2, NumExamples)\n",
        "X = tf.cast(X, tf.float32) # casting all the ints into tf.float32\n",
        "\n",
        "# define function to calulate Y\n",
        "def f(X):\n",
        "  return (X * ActualW) + ActualB\n",
        "\n",
        "# Create some noise\n",
        "Noise = tf.random.normal(shape=[NumExamples])\n",
        "\n",
        "# Calculate the actual y and add some noise\n",
        "Y = f(X) + Noise\n",
        "\n",
        "# calculate the loss\n",
        "def LossEval(T, YPred):\n",
        "  return tf.reduce_mean(tf.square(T - YPred))\n",
        "\n",
        "# Plot the data\n",
        "plt.plot(X, Y, ',', color= colours[4], label=\"Data\")\n",
        "plt.plot(X, f(X), ',', color= colours[4], label=\"Actual Data\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Footnote:- Tensors are usually treated on the batches/groups/inps and outps stacked together\n",
        "# Here small dataset hence do it in a single block"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "PI2z84yucnrY",
        "outputId": "e34e17df-456a-4252-d845-2f805880b53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create demo SLR model\n",
        "\n",
        "class DemoModel(tf.Module):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.weight = tf.Variable(5.0)\n",
        "    self.bias = tf.Variable(0.0) # usually random; not static like this one\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return (self.weight * x) + self.bias\n",
        "\n",
        "SLRDemo = DemoModel(name = \"My_model\")\n",
        "\n",
        "try:\n",
        "  assert SLRDemo(tf.constant(3.0)) == 15.0\n",
        "  print(\"good going\")\n",
        "except AssertionError:\n",
        "  print(\"Yeh toh hona hi tha!\")\n",
        "\n",
        "# Plot the actual predictions\n",
        "plt.plot(X, f(X), ',', color= colours[3], label=\"Actual Data\")\n",
        "plt.plot(X, SLRDemo(X), ',', label = \"Predictions\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Calculate the loss\n",
        "print(f\"The loss is {LossEval(Y, SLRDemo(X)).numpy() : .1f} %\")\n",
        "\n",
        "# Footnote:- to roundup use f\"{expression : .**decimals required**f}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "J1x2YBquhDNY",
        "outputId": "4c863c8b-be75-4e6e-cb9e-68ac7f059419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good going\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loss is  10.8 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a training loop using Keras\n",
        "\n",
        "# using previously made training dataset named 'X'!\n",
        "class KerasTLModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    # these paras here are static, usually contantly changing\n",
        "    self.weight = tf.Variable(5.0)\n",
        "    self.bias = tf.Variable(0.0)\n",
        "\n",
        "  def call(self, x):\n",
        "    return (self.weight * x) + self.bias\n",
        "\n",
        "AutoTLModel = KerasTLModel()\n",
        "\n",
        "# compile the training set parameters\n",
        "AutoTLModel.compile(run_eagerly = False,\n",
        "                    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
        "                    loss = tf.keras.losses.MeanSquaredError(reduction = \"sum_over_batch_size\"))\n",
        "print(X.shape[0])\n",
        "\n",
        "# actually fitting the models\n",
        "AutoTLModel.fit(X, Y, epochs = 10, batch_size = X.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l09tzqiHuTql",
        "outputId": "73482db4-f938-4e50-eb7c-bbb3f708d167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 10.7958\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 10.7958\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 10.7958\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 10.7958\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 10.7958\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 10.7958\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 10.7958\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 10.7958\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 10.7958\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 10.7958\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f185b86a420>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ]
}